---
layout: post
title: "Weekly Status Report: 2/11/25"
date: 2025-02-11 13:00:00
---

### Fails of the Week
So far, I’ve run into no distinct failures—though this is probably because I haven’t begun scraping the ATP data or building out the proposed SQL database yet. I expect that once I dive into that, I’ll run into plenty of obstacles, like figuring out how structured (or unstructured) the data is, whether historical datasets are easily accessible, and how computationally expensive frequent scraping would be. This is something I will begin diving into in the next couple of weeks.

### Successes of the Week
This week was all about laying the groundwork:

- Finalized the requirements document, clearly outlining objectives, data sources, and modeling approaches.  
- Investigated how the Match Charting Project data is structured—crucial for understanding how detailed shot-by-shot data can be used in playstyle modeling, and for planning how to structure the database.  
- Built a preliminary ER diagram, mapping out how the SQL database will handle players, matches, head-to-head data, and point-by-point tracking.  
- Thought through the architecture of the model and how different components might interact (though parts of this may be over-ambitious, so we will see how they fare once I begin building it out).

It’s been a solid start, and I feel like I have a clear vision for how the data will be structured moving forward.

### Challenges of the Week
While I didn’t hit any major blockers, one challenge was deciding on the best way to structure the database for long-term scalability. The more I looked into the Match Charting Project, the more I realized how granular the data gets—meaning I need to ensure the SQL structure remains efficient while handling thousands of individual points per match.

Also, integrating playstyle insights into a predictive model is still an open question. I now have a better idea of how to extract point construction patterns and some ideas for engineering features, but determining which features are actually predictive (and not just noise) is something I’ll need to experiment with once I build the model out.

I will also say, I definitely need to do more investigation into some of the baseline algorithms (e.g., Bradley-Terry, which is a frequently used sports prediction algorithm).

Another key challenge was deciding which dataset to start with. Since ATP and WTA operate as separate tours with different rankings, scheduling, and player pools, I decided to focus on ATP first before moving to WTA. This way, I can build and validate a single model before expanding, rather than trying to juggle both tours at once. It also simplifies the database structuring in the short term, since I don’t have to immediately worry about handling two distinct leagues. I chose the ATP simply because slightly more data is available.

### Goals for Next Week
Next up: ATP data deep dive. The plan is to:

- Further explore the ATP data structure  
  - What’s available historically? Are we limited to rolling 52-week values?
- Determine scraping feasibility  
  - How computationally expensive would it be to scrape ATP data regularly?
  - What’s the best frequency for updates (daily? weekly?)?
  - How is this data structured beyond general metrics?
- Once that’s sorted, I should have a clearer idea of how frequently I need to update the database and what kind of preprocessing pipelines will be necessary. In addition, this will give me a basis to begin collecting the data so I can combine it with the Match Charting Project data and actually start building out the proposed SQL database.

### Conclusions
Overall, this week was all about foundational setup and completing a requirements document. Next week will kick off my fuller exploration into data accessibility and integration.
